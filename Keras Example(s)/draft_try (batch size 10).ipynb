{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n",
      "Found 800 images belonging to 2 classes.\n",
      "Epoch 1/10\n",
      "200/200 [==============================] - 11s 57ms/step - loss: 0.7071 - acc: 0.5310 - val_loss: 0.6854 - val_acc: 0.5463\n",
      "Epoch 2/10\n",
      "200/200 [==============================] - 11s 54ms/step - loss: 0.6792 - acc: 0.5925 - val_loss: 0.6107 - val_acc: 0.6700\n",
      "Epoch 3/10\n",
      "200/200 [==============================] - 11s 56ms/step - loss: 0.6357 - acc: 0.6590 - val_loss: 0.6881 - val_acc: 0.6075\n",
      "Epoch 4/10\n",
      "200/200 [==============================] - 11s 56ms/step - loss: 0.6196 - acc: 0.6875 - val_loss: 0.5782 - val_acc: 0.7088\n",
      "Epoch 5/10\n",
      "200/200 [==============================] - 11s 57ms/step - loss: 0.5923 - acc: 0.6900 - val_loss: 0.5961 - val_acc: 0.6613\n",
      "Epoch 6/10\n",
      "200/200 [==============================] - 11s 57ms/step - loss: 0.5804 - acc: 0.7060 - val_loss: 0.5822 - val_acc: 0.6950\n",
      "Epoch 7/10\n",
      "200/200 [==============================] - 11s 56ms/step - loss: 0.5747 - acc: 0.7165 - val_loss: 0.5345 - val_acc: 0.7188\n",
      "Epoch 8/10\n",
      "200/200 [==============================] - 11s 57ms/step - loss: 0.5505 - acc: 0.7290 - val_loss: 0.5234 - val_acc: 0.7350\n",
      "Epoch 9/10\n",
      "200/200 [==============================] - 11s 55ms/step - loss: 0.5471 - acc: 0.7305 - val_loss: 0.6116 - val_acc: 0.6775\n",
      "Epoch 10/10\n",
      "200/200 [==============================] - 11s 56ms/step - loss: 0.5484 - acc: 0.7335 - val_loss: 0.5050 - val_acc: 0.7537\n"
     ]
    }
   ],
   "source": [
    "import os, os.path, re # ADDED, for dir operations\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras import backend as K\n",
    "\n",
    "def numSamples(path):\n",
    "    dirName = path\n",
    "    # Get the list of all files in directory tree at given path\n",
    "    listOfFiles = list()\n",
    "    for (dirpath, dirnames, filenames) in os.walk(dirName):\n",
    "        listOfFiles += [os.path.join(dirpath, file) for file in filenames]\n",
    "        # Get the total count from the full list of all files in dir and subdir\n",
    "        imgsInDir = [f for f in listOfFiles if re.search(r'.*\\.(jpg)$', f)]\n",
    "    return (len(imgsInDir)) # len() is required to return integer, else full list.\n",
    "\n",
    "img_wh = 150 # 'global' variable\n",
    "img_width, img_height = img_wh, img_wh # reduce modification to the original example\n",
    "train_data_dir = './dogs-vs-cats/data1/train/' # should not require changing if dir setup properly\n",
    "validation_data_dir = './dogs-vs-cats/data1/validation/' # should not require changing if dir setup properly\n",
    "nb_train_samples = numSamples(train_data_dir) # ADDED\n",
    "nb_validation_samples = numSamples(validation_data_dir) # ADDED\n",
    "epochs = 10\n",
    "batch_size = 10 # batch size determines \n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (3, img_width, img_height)\n",
    "else:\n",
    "    input_shape = (img_width, img_height, 3)\n",
    "\n",
    "# convnet Block 1 layer 1\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# convnet Block 1 layer 2\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# convnet Block 1 layer 3\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# Block 1 is connected to two fully-connected (fc) layers (flatten(fc1) and dense (fc2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64)) \n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid')) \n",
    "\n",
    "#Compile the model\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')\n",
    "\n",
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=nb_train_samples // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=nb_validation_samples // batch_size)\n",
    "\n",
    "model.save_weights('draft_try.h5') # always save after or during training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
