{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experimenting with TensorFlow, Keras, and Serving?\n",
    "\n",
    "References:\n",
    "https://medium.com/tensorflow/training-and-serving-ml-models-with-tf-keras-fd975cc0fa27\n",
    "\n",
    "Dataset:\n",
    "https://www.kaggle.com/c/planet-understanding-the-amazon-from-space/data\n",
    "\n",
    "The training data consists of approximately 40000 labeled images of the Amazon rain forest. Each image is associated with multiple labels:\n",
    "- Exactly one 'weather' label (clear/haze/cloudy/partly cloudy)\n",
    "- 'ground' labels (agriculture, bare ground, habitation, road, water...)\n",
    "The labels have been encoded as binary vectors as a .csv file.\n",
    "\n",
    "We want to train a model that can accurately predict these labels for new images. Weâ€™ll try to do this with a network that has two separate outputs for the weather and the ground labels. Predicting the weather labels is an example of a multi-class classification problem, whereas the ground labels can be modeled as a multi-label classification problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/mdl/.virtualenvs/test0/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/mdl/.virtualenvs/test0/lib/python3.6/site-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "# Building the model from scratch with a fairly classical conficuration\n",
    "# of convolutional layers, relu activations and two dense classifiers on top.\n",
    "\n",
    "import tensorflow as tf\n",
    "IM_SIZE = 128\n",
    "\n",
    "image_input = tf.keras.Input(shape=(IM_SIZE, IM_SIZE, 3), name='input_layer')\n",
    "\n",
    "# Some convolutional layers\n",
    "conv_1 = tf.keras.layers.Conv2D(32,\n",
    "                                kernel_size=(3, 3),\n",
    "                                padding='same',\n",
    "                                activation='relu')(image_input)\n",
    "conv_1 = tf.keras.layers.MaxPooling2D(padding='same')(conv_1)\n",
    "conv_2 = tf.keras.layers.Conv2D(32,\n",
    "                                kernel_size=(3, 3),\n",
    "                                padding='same',\n",
    "                                activation='relu')(conv_1)\n",
    "conv_2 = tf.keras.layers.MaxPooling2D(padding='same')(conv_2)\n",
    "\n",
    "# Flatten the output of the convolutional layers\n",
    "conv_flat = tf.keras.layers.Flatten()(conv_2)\n",
    "\n",
    "# Some dense layers with two separate outputs\n",
    "fc_1 = tf.keras.layers.Dense(128,\n",
    "                             activation='relu')(conv_flat)\n",
    "fc_1 = tf.keras.layers.Dropout(0.2)(fc_1)\n",
    "fc_2 = tf.keras.layers.Dense(128,\n",
    "                             activation='relu')(fc_1)\n",
    "fc_2 = tf.keras.layers.Dropout(0.2)(fc_2)\n",
    "\n",
    "# Output layers: separate outputs for the weather and the ground labels\n",
    "weather_output = tf.keras.layers.Dense(4,\n",
    "                                       activation='softmax',\n",
    "                                       name='weather')(fc_2)\n",
    "ground_output = tf.keras.layers.Dense(13,\n",
    "                                      activation='sigmoid',\n",
    "                                      name='ground')(fc_2)\n",
    "\n",
    "# Wrap in a Model\n",
    "model = tf.keras.Model(inputs=image_input, outputs=[weather_output, ground_output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss={'weather': 'categorical_crossentropy',\n",
    "                    'ground': 'binary_crossentropy'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "from tensorflow.keras.preprocessing.image import img_to_array as img_to_array\n",
    "from tensorflow.keras.preprocessing.image import load_img as load_img\n",
    "\n",
    "def load_image(image_path, size):\n",
    "    # data augmentation logic such as random rotations can be added here\n",
    "    return img_to_array(load_img(image_path, target_size=(size, size))) / 255.\n",
    "\n",
    "class KagglePlanetSequence(tf.keras.utils.Sequence):\n",
    "    \"\"\"\n",
    "    Custom Sequence object to train a model on out-of-memory datasets. \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, df_path, data_path, im_size, batch_size, mode='train'):\n",
    "        \"\"\"\n",
    "        df_path: path to a .csv file that contains columns with image names and labels\n",
    "        data_path: path that contains the training images\n",
    "        im_size: image size\n",
    "        mode: when in training mode, data will be shuffled between epochs\n",
    "        \"\"\"\n",
    "        self.df = pd.read_csv(df_path)\n",
    "        self.im_size = im_size\n",
    "        self.batch_size = batch_size\n",
    "        self.mode = mode\n",
    "\n",
    "        # Take labels and a list of image locations in memory\n",
    "        self.wlabels = self.df['weather_labels'].apply(lambda x: ast.literal_eval(x)).tolist()\n",
    "        self.glabels = self.df['ground_labels'].apply(lambda x: ast.literal_eval(x)).tolist()\n",
    "        self.image_list = self.df['image_name'].apply(lambda x: os.path.join(data_path, x + '.jpg')).tolist()\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(math.ceil(len(self.df) / float(self.batch_size)))\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        # Shuffles indexes after each epoch\n",
    "        self.indexes = range(len(self.image_list))\n",
    "        if self.mode == 'train':\n",
    "            self.indexes = random.sample(self.indexes, k=len(self.indexes))\n",
    "\n",
    "    def get_batch_labels(self, idx): \n",
    "        # Fetch a batch of labels\n",
    "        return [self.wlabels[idx * self.batch_size: (idx + 1) * self.batch_size],\n",
    "                self.glabels[idx * self.batch_size: (idx + 1) * self.batch_size]]\n",
    "\n",
    "    def get_batch_features(self, idx):\n",
    "        # Fetch a batch of images\n",
    "        batch_images = self.image_list[idx * self.batch_size: (1 + idx) * self.batch_size]\n",
    "        return np.array([load_image(im, self.im_size) for im in batch_images])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_x = self.get_batch_features(idx)\n",
    "        batch_y = self.get_batch_labels(idx)\n",
    "        return batch_x, batch_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Sequence object can be used instead of a custom generator together withfit_generator()to train the model. Note that there is no need to provide the number of steps per epoch, since the __len__ method implements that logic for the generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = KagglePlanetSequence('./KagglePlanetMCML.csv',\n",
    "                       './data/train/',\n",
    "                       im_size=IM_SIZE,\n",
    "                       batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model on a single epoch\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.ModelCheckpoint('./model.h5', verbose=1)\n",
    "]\n",
    "\n",
    "model.fit_generator(generator=seq,\n",
    "                    verbose=1, \n",
    "                    epochs=1,\n",
    "                    use_multiprocessing=True,\n",
    "                    workers=4,\n",
    "                    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_seq = KagglePlanetSequence('./KagglePlanetMCML.csv',\n",
    "                       './data/train/',\n",
    "                       im_size=IM_SIZE,\n",
    "                       batch_size=32, mode='test')\n",
    "predictions = model.predict_generator(generator=test_seq, verbose=1)\n",
    "len(predictions[1])  == len(df_train) # This is True!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wait, what about the Dataset API?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
